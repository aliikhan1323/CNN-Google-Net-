# -*- coding: utf-8 -*-
"""CNN imp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qI7Ul_mZz4G7cU2voUYmfwOK2y85VmOU
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
from torchvision.models import googlenet

transform = transforms.Compose([
    transforms.Resize((224,224)),  # GoogLeNet input size
    transforms.RandomHorizontalFlip(),
    transforms.RandomCrop(224, padding=4),
    transforms.ToTensor(),
])

trainset = torchvision.datasets.CIFAR10(root="./data", train=True, download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)

testset = torchvision.datasets.CIFAR10(root="./data", train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)

device = "cuda" if torch.cuda.is_available() else "cpu"

model = googlenet(pretrained=True) # Model Loading
model.fc = nn.Linear(1024, 10)  # CIFAR-10 classes = 10
model.to(device)

"""**Loss Function & Optimizer.**

**CrossEntropyLoss()**



* Used for multi-class classification
* Measures how far model predictions are from the correct class labels

**Adam Optimizer**

Adjusts model weights to reduce loss

* Adjusts model weights to reduce loss
* lr=0.0005 = learning rate (how fast the model learns)





"""

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0005) #Learning Rate

epochs = 5      # Train for 5 rounds.
for epoch in range(epochs):  # Loop through each training round.
    model.train()            # Set model to training mode.
    running_loss = 0.0       # Start loss count for this epoch.
    for images, labels in trainloader:
        images, labels = images.to(device), labels.to(device)   # Move data to GPU/CPU for faster training.

        optimizer.zero_grad()              # 1️⃣ Clear previous gradients
        outputs = model(images)            # 2️⃣ Forward pass (predict)
        loss = criterion(outputs, labels)  # 3️⃣ Calculate loss
        loss.backward()                    # 4️⃣ Backpropagation (compute gradients)
        optimizer.step()                   # 5️⃣ Update model weights
        # running_loss = running_loss + loss.item()
        running_loss += loss.item()        # Adds batch loss to keep total loss for that epoch

    print(f"Epoch {epoch+1}, Loss: {running_loss/len(trainloader):.4f}")  # Shows average loss per epoch